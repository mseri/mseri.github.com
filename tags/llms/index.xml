<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Llms on A fractal spectrum of tales</title><link>https://www.mseri.me/tags/llms/</link><description>Recent content in Llms on A fractal spectrum of tales</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 26 Jul 2024 11:14:09 +0200</lastBuildDate><atom:link href="https://www.mseri.me/tags/llms/index.xml" rel="self" type="application/rss+xml"/><item><title>unning LLMs Locally With Ollama</title><link>https://www.mseri.me/unning-llms-locally-with-ollama/</link><pubDate>Fri, 26 Jul 2024 11:14:09 +0200</pubDate><guid>https://www.mseri.me/unning-llms-locally-with-ollama/</guid><description>In my previous post, I explored various ways to run Large Language Models locally. Since that post, I have been pointed to try another powerful tool for this purpose: Ollama. This open-source project makes it incredibly easy to run LLMs on your local machine, offering a great balance between simplicity and flexibility.
While it does not seem as flexible as the llm python library I presented in the other post and it can scare some users with its command-line interface, I was impressed by its ease of use and the wide range of models it supports.</description></item><item><title>Running LLMs locally</title><link>https://www.mseri.me/running-llms-locally/</link><pubDate>Wed, 24 Jul 2024 18:37:42 +0200</pubDate><guid>https://www.mseri.me/running-llms-locally/</guid><description>Large Language Models (LLMs) are powerful tools for generating human-like text responses. You might be familiar with them through services like ChatGPT, Anthropic Claude, Google Gemini, and Perplexity AI, Nowadays people are using them for editing purposes, writing, brainstorming, and even for generating code snippets. When used responsibly and critically as a tool to assist human creativity, they can be very helpful.
Recently, I spent some time playing with these models and I found them fascinating.</description></item></channel></rss>