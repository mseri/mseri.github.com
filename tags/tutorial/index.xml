<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tutorial on A fractal spectrum of tales</title><link>https://www.mseri.me/tags/tutorial/</link><description>Recent content in Tutorial on A fractal spectrum of tales</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Fri, 26 Jul 2024 11:14:09 +0200</lastBuildDate><atom:link href="https://www.mseri.me/tags/tutorial/index.xml" rel="self" type="application/rss+xml"/><item><title>Running LLMs Locally With Ollama</title><link>https://www.mseri.me/running-llms-locally-with-ollama/</link><pubDate>Fri, 26 Jul 2024 11:14:09 +0200</pubDate><guid>https://www.mseri.me/running-llms-locally-with-ollama/</guid><description>&lt;p>In &lt;a href="https://www.mseri.me/running-llms-locally/">my previous post&lt;/a>, I explored various ways to run Large Language Models locally.
Since that post, I have been pointed to try another powerful tool for this purpose: &lt;a href="https://ollama.com/">Ollama&lt;/a>.
This open-source project makes it incredibly easy to run LLMs on your local machine, offering a great balance between simplicity and flexibility.&lt;/p>
&lt;p>While it does not seem as flexible as the &lt;code>llm&lt;/code> python library I presented in the other post and it can scare some users with its command-line interface, I was impressed by its ease of use and the wide range of models it supports.
I am not overselling this, its simplicity is staggering: you can get started with just a few commands.&lt;/p></description></item><item><title>Running LLMs locally</title><link>https://www.mseri.me/running-llms-locally/</link><pubDate>Wed, 24 Jul 2024 18:37:42 +0200</pubDate><guid>https://www.mseri.me/running-llms-locally/</guid><description>&lt;p>Large Language Models (LLMs) are powerful tools for generating human-like text responses. You might be familiar with them through services like &lt;a href="https://chat.openai.com/">ChatGPT&lt;/a>, &lt;a href="https://claude.ai/">Anthropic Claude&lt;/a>, &lt;a href="https://gemini.google.com/">Google Gemini&lt;/a>, and &lt;a href="https://www.perplexity.ai/">Perplexity AI&lt;/a>,
Nowadays people are using them for editing purposes, writing, brainstorming, and even for generating code snippets.
When used &lt;strong>responsibly and critically&lt;/strong> as a tool to assist human creativity, they can be very helpful.&lt;/p>
&lt;p>Recently, I spent some time playing with these models and I found them fascinating. However, due to privacy concerns and their high environmental costs, I don&amp;rsquo;t feel comfortable using cloud-based services.
This post is an account of my experience with running LLMs locally on my machines.
This can be quite straightforward, and if you have 8-16GB of RAM and a decent GPU, you can run these models on your own computer without significant issues.&lt;/p></description></item><item><title>Move to ghc 7.8.2 on MacOSX</title><link>https://www.mseri.me/move-to-ghc-7-8-2-on-macosx/</link><pubDate>Sun, 01 Jun 2014 15:17:42 +0000</pubDate><guid>https://www.mseri.me/move-to-ghc-7-8-2-on-macosx/</guid><description>&lt;p>Lately I&amp;rsquo;ve been playing with some functional languages: &lt;a href="https://www.haskell.org/">haskell&lt;/a>, lisp (in particular the scheme dialect, see e.g. &lt;a href="https://www.call-cc.org">chicken&lt;/a> or &lt;a href="https://racket-lang.org">racket&lt;/a>) and &lt;a href="https://elixir-lang.org">elixir&lt;/a> (I very much like it and I really appreciate that it runs on the erlang VM).&lt;/p>
&lt;p>Each of those has something pretty unique and I believe is very worth learning. I cannot stress how much material you can find both online and in libraries to learn them (except for elixir but its website does a really good job and there will be plenty of books very soon out) and how strong thay can change your way of programming.&lt;/p></description></item><item><title>Installing Scientific Python 3 libraries on OSX (and julia with IJulia)</title><link>https://www.mseri.me/installing-scientific-python-3-libraries-on-osx-and-julia-with-ijulia/</link><pubDate>Tue, 15 Apr 2014 13:35:03 +0000</pubDate><guid>https://www.mseri.me/installing-scientific-python-3-libraries-on-osx-and-julia-with-ijulia/</guid><description>&lt;p>In a recent post, I tried to explain how to &lt;a href="https://www.mseri.me/installing-scientific-python-libraries-on-osx/">install scientific python libraries on OSX and get rid of the most common errors&lt;/a>. In that case everythong I did was for python 2.7.&lt;/p>
&lt;p>Yesterday I decided to fully move to python 3.4. I&amp;rsquo;ve removed my python installation via homebrew and with it all the installed packages.&lt;/p>
&lt;p>Moving to python 3 is straightforward if you have done the procedure described in &lt;a href="https://www.mseri.me/installing-scientific-python-libraries-on-osx/">my previous post&lt;/a>, it all really reduces to replace every occurrence of &lt;code>python&lt;/code> in that post with &lt;code>python3&lt;/code> and every occurrence of &lt;code>pip&lt;/code> with &lt;code>pip3&lt;/code>.&lt;/p></description></item><item><title>Installing scientific python libraries on OSX</title><link>https://www.mseri.me/installing-scientific-python-libraries-on-osx/</link><pubDate>Wed, 19 Feb 2014 19:06:40 +0000</pubDate><guid>https://www.mseri.me/installing-scientific-python-libraries-on-osx/</guid><description>&lt;p>For a recent project, I had the necessity to install (or update) some of the scientific python libraries that I use for computation (and to avoit matlab). I was aware of &lt;a href="https://www.thisisthegreenroom.com/2011/installing-python-numpy-scipy-matplotlib-and-ipython-on-lion/">a not too recent tutorial&lt;/a> in regard that left me quit unhappy at the time, in particular I strongly disagree with their practice of changing OSX official symlinks to point at the new Python install.&lt;/p>
&lt;p>Given that I am not alone in the project, I decided to write a short tutorial trying to include all the necessary steps for a successful installation of python, numpy, scipy, matplotlib, ipython and qutip.&lt;/p></description></item><item><title>Git workflow for lazy mathematicians</title><link>https://www.mseri.me/git-workflow-for-lazy-mathematicians/</link><pubDate>Mon, 21 Oct 2013 16:40:27 +0000</pubDate><guid>https://www.mseri.me/git-workflow-for-lazy-mathematicians/</guid><description>&lt;p>This post is pretty old, You can refer to &lt;a href="https://www.mseri.me/a-brief-intro-to-git/">my new post here&lt;/a> for a more modern version.&lt;/p>
&lt;p>First of all, what is &lt;a href="https://git-scm.com">git&lt;/a>? Citing its website&lt;/p>
&lt;blockquote>
&lt;p>Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency.
[It] is easy to learn and has a tiny footprint with lightning fast performance.&lt;/p>
&lt;/blockquote>
&lt;p>In other words Git provides a source control repository that enables you to roll back code changes as needed, to merge the updates when collaborating with others and eventually to have an online backup of your work.&lt;/p></description></item><item><title>Ghost up and running on Amazon EC2</title><link>https://www.mseri.me/ghost-up-and-running-on-amazon-ec2/</link><pubDate>Mon, 23 Sep 2013 11:00:00 +0000</pubDate><guid>https://www.mseri.me/ghost-up-and-running-on-amazon-ec2/</guid><description>&lt;p>I had my free Amazon EC2 instance waiting for this moment since &lt;a href="https://github.com/mseri/pplofthesoil">my last use of it&lt;/a>.&lt;/p>
&lt;p>I spent my few free hours setting up a decent (I hope) &lt;a href="https://github.com/mseri/purity">theme&lt;/a> for &lt;a href="https://ghost.org">Ghost&lt;/a>, and reading around what to do and what not to do to have it up and running. My main reference was the nice blog post &lt;a href="https://www.howtoinstallghost.com/how-to-setup-an-amazon-ec2-instance-to-host-ghost-for-free/">How to set up an Amazon EC2 instance to host ghost for free&lt;/a>.&lt;/p>
&lt;p>I followed more or less all the steps suggested in the guide but there was still something missing: I wanted my Ghost blog to be running even when I am not logged in the EC2 instance.&lt;/p></description></item></channel></rss>